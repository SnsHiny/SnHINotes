# Reptile Theory

- 爬虫在使用场景中的分类
	- 通用爬虫：抓取系统重要组成部分，抓取的是一整张页面数据
	- 聚焦爬虫：是建立在通用爬虫的基础之上，抓取的是页面中特定的局部内容
	- 增量式爬虫：监测网站中数据更新的情况，只会抓取网站中最新更新出来的数据
- 反爬机制
	- 门户网站可以通过制定相应的策略或者技术手段，防止爬虫程序进行网站数据的爬取
- 反反爬策略
	- 爬虫程序可以通过制定相关的策略或者技术手段，破解门户网站中具备的反爬机制，从而可以获取门户网站的数据
- robots.txt协议
	- 君子协议，规定了网站中哪些数据可以被爬取哪些数据不可以被爬取

- http协议
	- 概念：服务器与客户端进行数据交互的一种形式
- 常用请求头信息（Request Headers）
	- User-Agent：请求载体（浏览器）的身份标识
	- Connection：请求完毕后，是断开连接还是保持连接
- 常用响应头信息
	- Content-Type：服务器响应回客户端的数据类型
- https协议
	- 安全（数据加密）的http协议
- 数据加密方式
	- 对称密钥加密：客户端将将要发送的数据进行加密，并将加密后的数据和密钥同时发送给服务器，服务器端通过密钥将加密的数据解密，得到原数据。此方法存在安全隐患，可能会被三方机构同时拦截密钥和密文，数据将被暴露。
	- 非对称密钥加密（公开密钥加密）：使用这种加密方式有两把锁，一把叫“私有秘钥”，一把叫“公开密钥”，服务器首先告诉客户端按照自己给定的公开密钥进行数据加密，客户端加密后发送给服务器，服务器再通过私有秘钥进行解密。这样做的好处是解密的钥匙不会进行传输也就避免了被拦截。但是这种加密方式效率较低从而影响通信速度，并且公钥也有被拦截并且篡改的风险，无法保证客户端收到的公开密钥就是服务器发送的公开密钥。
	- 证书密钥加密（https）：数字证书认证机构是客户端和服务器端都可信赖的第三方机构，首先服务器携带公开密钥向数字证书认证机构提出公开密钥的申请，数字证书认证机构在认清申请者的身份审核通过以后，会对公开密钥做数字签名，并将密钥放在证书里面绑定在一起，发送证书以及公开密钥给客户端，客户端可通过数字签名来验证公钥的真伪，一旦确定信息无误后，客户端就会通过公钥对报文进行加密发送，服务器收到以后用自己的私钥进行解密。

# Requests 模块

- requests模块：Python中原生的一款基于网络请求的模块
- 作用：模拟浏览器发送请求
- 步骤
	- 指定url
	- 发起请求
	- 获取响应数据
	- 持久化存储
- 环境安装
	
	- pip install requests
- UA
	
	- User-Agent（请求载体的身份标识）
- UA检测
	
	- 门户网站的服务器会检测对应请求的载体身份标识，如果检测到的为某一款浏览器说明该请求是一个正常的请求。但是如果检测到的请求的载体身份标识不是基于一款浏览器的，则表示为不正常的请求（爬虫），则服务器就很有可能拒绝该次请求。
- UA伪装
	
	- 让爬虫对应的请求载体身份标识伪装成某一款浏览器
	
	
